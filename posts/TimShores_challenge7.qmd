---
title: "Challenge 7"
author: "Tim Shores"
description: "Visualizing Multiple Dimensions"
date: "04/17/2022"
format:
  html:
    df-print: paged
    toc: true
    code-fold: true
    code-copy: true
    code-tools: true
categories:
  - challenge_7
  - usa_households

---

```{r}
#| label: setup
#| warning: false
#| message: false

my_packages <- c("tidyverse", "readxl", "ggplot2", "knitr") # create vector of packages
invisible(lapply(my_packages, require, character.only = TRUE)) # load multiple packages

knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

## Challenge Overview

Today's challenge is to:

1)  read in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)
2)  tidy data (as needed, including sanity checks)
3)  mutate variables as needed (including sanity checks)
4)  Recreate at least two graphs from previous exercises, but introduce at least one additional dimension that you omitted before using ggplot functionality (color, shape, line, facet, etc) The goal is not to create unneeded [chart ink (Tufte)](https://www.edwardtufte.com/tufte/), but to concisely capture variation in additional dimensions that were collapsed in your earlier 2 or 3 dimensional graphs.
   - Explain why you choose the specific graph type
5) If you haven't tried in previous weeks, work this week to make your graphs "publication" ready with titles, captions, and pretty axis labels and other viewer-friendly features

[R Graph Gallery](https://r-graph-gallery.com/) is a good starting point for thinking about what information is conveyed in standard graph types, and includes example R code. And anyone not familiar with Edward Tufte should check out his [fantastic books](https://www.edwardtufte.com/tufte/books_vdqi) and [courses on data visualizaton.](https://www.edwardtufte.com/tufte/courses)

(be sure to only include the category tags for the data you use!)

## Read in data

I chose to read in the USA Households Excel spreadsheet.

```{r}

df_USHouseholds <- read_excel("../posts/_data/USA Households by Total Money Income, Race, and Hispanic Origin of Householder 1967 to 2019.xlsx", na = "N") # the Excel workbook has one worksheet to read in. Empty values are represented by cells with character "N".

df_USHouseholds

```

### Briefly describe the data

## Tidy Data (as needed)

Is your data already tidy, or is there work to be done? Be sure to anticipate your end result to provide a sanity check, and document your work here.

```{r}

  # capture info from header and footnotes in a separate df
df_footnotes <- df_USHouseholds %>%
  slice(1:2, 358:n()) %>%
  setNames(c("dataHeaderAndFootnotes"))

  # the big tidy and mutation spree on the primary df
df_USHouseholds <- df_USHouseholds %>%
    # don't need the header
  slice(-(1:2)) %>%
    # renaming just to make the next line of code easier to read
  rename(hh_yrh_origin = 1) %>%
    # by making 3 copies of this column, I can more easily tidy up values
  mutate(year = hh_yrh_origin, hh_RaceHisp = hh_yrh_origin, footnote = hh_yrh_origin) %>%
    # moving my new columns to the beginning
  relocate(c("year", "hh_RaceHisp", "footnote")) %>%
    # erase end notes
  mutate(across(c("year","hh_RaceHisp","footnote"), str_replace, '^Note:.+$|^Source:.+$|^N\\s.+$|^\\d{1,2}\\s.+$', '')) %>%
    # erase text labels
  mutate(across(year, str_replace, '^[[:alpha:]]+[[:alpha:],()\\d\\s\\\\]+$', '')) %>%
    # erase commas
  mutate(across(year, str_replace, '[,]', '')) %>%
    # erase superscript digits
  mutate(across(year, str_replace, '\\s[\\d\\s]+$', '')) %>%
    # erase year and space
  mutate(across(c("hh_RaceHisp","footnote"), str_replace, "^\\d{4}\\s?", '')) %>%
    # erase superscript digits
  mutate(across(hh_RaceHisp, str_replace, "\\d{1,2}", '')) %>%
    # erase superscript digits with comma
  mutate(across(hh_RaceHisp, str_replace, ",\\s\\d{1,2}", '')) %>%
    # erase \r\n
  mutate(across(c("hh_RaceHisp","footnote"), str_replace, "\r\n.*$", '')) %>%
    # replace empty values with NA
  mutate(across(c("year","hh_RaceHisp","footnote"), ~ifelse(.=="", NA, as.character(.)))) %>%
    # populate hh_RaceHisp column with values
  fill(hh_RaceHisp) %>%
    # omit unnecessary columns
  select(-c("hh_yrh_origin","...3")) %>%
    # tidy up column names for the rest of the table
  rename(
    hh_numInThousands = ...2,
    est_medIncomeInDollars = ...13,
    margErr_medIncomeInDollars = ...14,
    est_meanIncomeInDollars = ...15,
    margErr_meanIncomeInDollars = ...16
  ) %>%
    # remove rows where year is NA
  filter(!is.na(year)) %>%
    # convert data types
  mutate(
    hh_RaceHisp = factor(hh_RaceHisp),
    year = make_date(year = year, month = 1, day = 1),
    across(hh_numInThousands:margErr_meanIncomeInDollars, as.numeric)
    ) %>%
    # make it long for better normalization
  pivot_longer(
    cols = ...4:...12,
    names_to = "income",
    values_to = "percentDistribution"
  ) %>%
    # Update the income text to match the original data headers
  mutate(
    income = case_match(
      income,
      "...4" ~ "Under $15,000",
      "...5" ~ "$15,000 to $24,999",
      "...6" ~ "$25,000 to $34,999",
      "...7" ~ "$35,000 to $49,999",
      "...8" ~ "$50,000 to $74,999",
      "...9" ~ "$75,000 to $99,999",
      "...10" ~ "$100,000 to $149,999",
      "...11" ~ "$150,000 to $199,999",
      "...12" ~ "$200,000 and over"
    ),
    # Convert income to factor and set levels to match numerical order
    income = factor(income, levels = c("Under $15,000", "$15,000 to $24,999", "$25,000 to $34,999", "$35,000 to $49,999", "$50,000 to $74,999", "$75,000 to $99,999", "$100,000 to $149,999", "$150,000 to $199,999", "$200,000 and over"))) %>%
    # put this at the beginning
  relocate(c("income", "percentDistribution"), .after = footnote) %>%
    # sort
  arrange(year, hh_RaceHisp, income, footnote)

df_USHouseholds
df_footnotes

```

Are there any variables that require mutation to be usable in your analysis stream? For example, do you need to calculate new values in order to graph them? Can string values be represented numerically? Do you need to turn any variables into factors and reorder for ease of graphics and visualization?

Document your work here.

```{r}
# count unique and missing values
df_USHouseholds %>% summarize(
  yearNA = sum(is.na(year)),
  hh_RaceHispNA = sum(is.na(hh_RaceHisp)),
  footnoteNA = sum(is.na(footnote)),
  incomeNA = sum(is.na(income)),
  percentDistributionNA = sum(is.na(percentDistribution)),
  hh_numInThousandsNA = sum(is.na(hh_numInThousands))
  )

# The second set is less important to my analysis and has a lot of NAs
df_USHouseholds %>% summarize(  
  est_medIncomeInDollarsNA = sum(is.na(est_medIncomeInDollars)),
  margErr_medIncomeInDollarsNA = sum(is.na(margErr_medIncomeInDollars)),
  est_meanIncomeInDollarsNA = sum(is.na(est_meanIncomeInDollars)),
  est_meanIncomeInDollarsNA = sum(is.na(est_meanIncomeInDollars)),
  margErr_meanIncomeInDollarsNA = sum(is.na(margErr_meanIncomeInDollars))
  )


# these two groupings reveal which years are duplicated by footnotes: 2013 (with footnotes 3 and 4) and 2017 (with footnote 2)

df_USHouseholds %>% 
  group_by(year,hh_RaceHisp) %>%
  summarize(
    countIncome = n(),
    sumPD = sum(percentDistribution),
    numMean = mean(hh_numInThousands)
    ) %>%
  subset(select = c(year, hh_RaceHisp, countIncome, sumPD, numMean))

df_USHouseholds %>% 
  group_by(year,footnote) %>%
  summarize(
    countFeet = n()
    ) %>%
  subset(select = c(year, footnote, countFeet))

# These are the footnotes for 2013. Based on this, it sounds like 2013^4 is the corrected data. I will omit 2013^3.

# 3 The 2014 CPS ASEC included redesigned questions for income and health insurance coverage. All of the approximately 98,000 addresses were eligible to receive the redesigned set of health insurance coverage questions. The redesigned income questions were implemented to a subsample of these 98,000 addresses using a probability split panel design. Approximately 68,000 addresses were eligible to receive a set of income questions similar to those used in the 2013 CPS ASEC and the remaining 30,000 addresses were eligible to receive the redesigned income questions. The source of these 2013 estimates is the portion of the CPS ASEC sample which received the redesigned income questions, approximately 30,000 addresses.	
# 4 The source of these 2013 estimates is the portion of the CPS ASEC sample which received the income questions consistent with the 2013 CPS ASEC, approximately 68,000 addresses.

# This is the footnote for 2017. Again, a correction. Therefore, I will omit the 2017^NA rows.

# 2 Estimates reflect the implementation of an updated data processing system, allowing users to evaluate the impact, and should be used to make comparisons to 2018 and subsequent years. \r\n

# filtering with NAs in play is tricky...
df_USHouseholdsFILTER <- df_USHouseholds %>%
  filter(is.na(footnote) | (year != '2013-01-01' | footnote != 3))

df_USHouseholdsFILTER <- df_USHouseholdsFILTER %>%
  filter((is.na(footnote) & year != '2017-01-01') | (!is.na(footnote)))

# sanity check the results

df_USHouseholdsFILTER

df_USHouseholdsFILTER %>% 
  group_by(year,hh_RaceHisp) %>%
  summarize(
    countIncome = n(),
    sumPD = sum(percentDistribution),
    numMean = mean(hh_numInThousands)
    ) %>%
  subset(select = c(year, hh_RaceHisp, countIncome, sumPD, numMean))

df_USHouseholdsFILTER %>% 
  group_by(year,footnote) %>%
  summarize(
    countFeet = n()
    ) %>%
  subset(select = c(year, footnote, countFeet))

```

## Visualization with Multiple Dimensions

```{r}

# footnotes complicate things and introduce duplicate rows.
ggplot(filter(df_USHouseholds, str_detect(hh_RaceHisp, "WHITE")), aes(x=year, y=est_medIncomeInDollars, fill=hh_RaceHisp)) +
  #geom_line() + 
  geom_bar(position="stack", stat="identity") +
  #geom_smooth(method=lm, level=0.95, show.legend=TRUE) +
  labs(title = "Change in estimated median income (dollars)",
              subtitle = "Plot of all observations",
              caption = "Data source: USA Households [...] 1967 to 2019.xlsx",
              x = "Year", y = "Estimated Median Income (Dollars)",
              ) +
  theme(axis.text.x = element_text(face="bold", color="#993333", 
                           size=12),
          axis.text.y = element_text(face="bold", color="#993333", 
                           size=12)) +
  scale_x_date(date_breaks = "10 years" , date_labels = "%Y")

```