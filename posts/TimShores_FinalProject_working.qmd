---
title: "Final Project Assignment #2: Tim Shores"
author: "Tim Shores"
description: "Project & Data Description"
date: "04/09/2023"
format:
  html:
    df-print: paged
    toc: true
    code-copy: true
    code-tools: true
    code-fold: true
    code-overflow: wrap
    css: styles.css
categories:
  - final_Project_assignment_1
  - final_project_data_description
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| warning: false
#| message: false

my_packages <- c("tidyverse", "fs", "pdftools", "knitr", "ggplot2", "viridis", "hrbrthemes", "gridExtra") # create vector of packages
invisible(lapply(my_packages, require, character.only = TRUE)) # load multiple packages

knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)


```

### Summary

This is the story of two small, rural Massachusetts towns that have made an agreement to combine their two local police departments into a single regionalized department. The goal of regionalization, initiated in 2020, is to reduce cost by sharing a service. However, regionalization has made it more challenging for the towns to assess personnel needs of their police and other public safety services. 

For example, if demand for first responders has increased, is it because a single police department is now responding to calls from both towns, or is it for reasons unrelated to regionalization, such as increased police response to medical calls or other calls for which police response is not required?

I intend to use the data collected to better inform budgeting and public safety discussion by public officials in the two towns. Furthermore, the work of regionalized municipal services is a common challenge that small rural towns, strapped for revenue, must consider. Improving how we collect and derive insights from municipal service regionalization data will be a vital service to towns who often don't have the capacity to organize their own data-driven policy and administration.

::: {.callout-warning icon=false}

## Research question

**What is the nature of public safety need behind the increase in calls that police respond to?**

:::


### Background

Since 2020, I have volunteered my time as a community organizer and political office-holder in the small rural town of Leverett, Massachusetts. Some of the key challenges of public administration in Leverett are a high property tax rate,   unaffordability, the needs of an aging population, lack of transportation, lack of access to commerce and health service, lack of access to public process, and lack of resources for gathering good evidence for public decision-making.

At the recent budget meetings in Spring 2023, the Leverett Police Chief made a budget request for a fourth full-time officer position. This position would help the Police Department overcome these problems:

1. Decreased supply of police officer human resources due to state criminal justice reform.
2. Increased demand for police officer human resources due to increased call volume in the towns of Leverett and Wendell.

::: {.callout-tip icon=false}

## Problem #1 in detail

**How has state reform decreased supply of police officers?**

:::

Since 2021, state POST reform has made it [difficult for local police departments](https://www.berkshireeagle.com/news/central_berkshires/lenox-police-chief-talks-impact-of-new-rules-for-part-time-officers/article_3949b04c-35b2-11ec-8169-a72d6e4669a8.html) to fill their on-duty schedules with reserve police officers. Before 2021, reserve officers required half as much training as full-time officers. Reserve officers could work part-time and as a second job in seasonal positions or on shifts as-needed could do so with lower training requirements. The State of Massachusetts Peace Officer Standards and Training (POST) Commission has enacted a series of reforms that increased the amount of training required by reserve officers. Reserves must now train as much as full-time officers. This has removed an incentive and reduced the availability of reserve officers. Local police departments now struggle to meet their scheduling needs and turn to requests for more full-time positions.

::: {.callout-tip icon=false}

## Problem #2 in detail

**How much and why has call volume increased in Leverett and Wendell?**

:::

Since 2020, when the Wendell chief of police retired, the neighboring towns of Leverett and Wendell have agreed to combine their municipal police service. Wendell closed its own police department (WPD), and began to allocate its police budget revenue to the Leverett Police Department (LPD). LPD took responsibility for responding to police and emergency calls from both Leverett and Wendell. This regionalization of municipal service is expected to reduce public safety costs over time, although in the short-term it appears that Leverett has paid for more police expenses compared to Wendell's share. Meanwhile, LPD is still adjusting to the change in demand for police service, which shows up as an increase in call volume that officers respond to.  

To solve these problems, Leverett Chief of Police Scott Minckler proposed that Leverett hire a fourth full-time officer. 

The request was approved by the Leverett and Wendell Police Services Oversight committee, the Leverett Personnel Board, and the Leverett Finance Committee. When the matter came before the Leverett Selectboard budget meeting, some members of town government and the public wanted to know more detail about the increase in call volume. 

::: {.callout-tip icon=false}

## Questions of public interest

a. What types of calls are increasing? 
b. What is the change in personnel time needed per call and per type of call?
c. What days and times of day do we see the most calls or the most change in calls?
d. Why do we need another officer when the populations and number of properties in the two towns have not grown substantially?

:::

Chief Minckler's responses to these questions were informed by his administrative experience, but not by call data analysis. Due to difficulties generating reports from the administrative software used by many emergency response departments, the Chief was not able to use call data to do more than track call volume and call type. The Chief was not able to answer questions about the nature of increased calls: Were they violent crime, domestic violence, interpersonal conflict, fraud, property rights violations, traffic violations, medical emergencies, mental health emergencies, fires? 

Although people had multiple concerns and interests in the matter, most meeting participants had this basic question in common: 

::: {.callout-warning icon=false}

## Research question

**What is the nature of public safety need behind the increase in calls that police respond to?**

:::

In other words, if we hire another police officer, will that meet the public safety need? If our increased needs are by nature medical, mental health, fire, or community health and well-being, then **we risk misallocating public resources in a solution to the wrong problem**.


### Dataset Introduction
To collect data that could help understand more about the public safety need of Leverett and Wendell, I submitted this [public records request](https://www.mass.gov/info-details/massachusetts-law-about-freedom-of-information-and-public-records):

::: {.callout-note icon=false}

## Email to PD: Thu, Mar 30, 2023 at 3:00 PM

Subject: Public Records Request for Leverett PD call data
To: Scott D. Minckler <policechief@leverett.ma.us>

Hi Chief Minckler,

I also left a voicemail, but thought it would help to send my request by email. I've been learning about the budget requests from last week's meeting to get a sense of the request and the call volume and any other factors behind the request. It would help if I could learn more about our call data. 

I'm writing to request public data to do with Leverett and Wendell calls made to dispatch, and calls handled by our police department, for the 5-year period 2018 to 2022 (inclusive of the years 2018, 2019, 2020, 2021, and 2022). I'm requesting complete police department call detail records, with columns of data redacted if they are subject to specific statutory exemption to the MA Public Records Law due to criteria such as victim confidentiality. 

Please export data from your call management software application to CSV or XLSX files, rather than PDF or Word documents. The tabular CSV or XLSX format will facilitate data analysis.  

If the export files are too large for email attachment, please upload to this Drive location: 

*url omitted*

Thanks! Let me know if you have any questions or feedback.

Tim Shores

:::

Chief Minckler called me the following Monday morning to discuss the request. He could supply reports, but not at the level of detail that I requested. I learned more about the challenges of pulling reports. I also learned from Chief Minckler that one reason for the growth of calls in Wendell was that the former police chief of Wendell did not record every call. This was not made known at the time when the two towns negotiated their regionalization agreement. 

I spoke with Supervisor Butch Garrity of Shelburne Dispatch, which serves as the 911 dispatcher for most towns in Franklin County, including Leverett and Wendell. The dispatch center and local agencies have used a client-server application called [IMC-Central Square](https://www.centralsquare.com/) since 1997 to manage dispatch calls and responses. The application has a reputation for being difficult to use and limited in functionality.

::: {.callout-warning icon=false}

### IMC-Central Square report limitations

1. The report export format was limited to PDF.
2. They could only provide call summary data. It was not practical to provide call detail data that would include relevant information (such as call day and time of day, location, demographics of people involved, and details of actions taken by responding officers) because Central Square has no redaction functions. 
:::

These software limitations have come up before in Leverett. In 2020, the town of Leverett appointed residents to a Social Justice Committee (SJC). While researching a report on policing and the experience of people of color in Leverett, the SJC submitted multiple requests for police call data that included race and ethnicity of people involved in calls. LPD claimed that they were not able to comply because they were unable to generate reports for anything more detailed than than call volume grouped by call reason. The SJC met with someone at Amherst PD, which uses the same software, who offered to meet with LPD about how to generate IMC-Central Square reports. I am not aware of any follow-through on that offer for inter-departmental collaboration on the SJC public records request.

Based on my career experience with numerous database systems, I'm confident that technical means exist to overcome these functional limits. However, I take the claims of the LPD and Shelburne Dispatch to be made in good faith. At the end of the day, it comes down to a lack of resources, and as a researcher I must set my expectations accordingly.

Chief Minckler sent me 10 PDF files: one for each town and year, from 2018 to 2022. Each file includes 3 tables:

::: {.callout-note icon=false}

## Source report structure

1. **Call Reason Breakdown** shows the number of calls for each call reason, average time per call per call reason, and the type and number of actions taken in response to each call reason.
2. **Call Action Breakdown** shows summaries of call actions.
3. **Operator Race and Sex Breakdown** shows demographics of vehicle operators involved in traffic stops and violations.
:::

**Call Reason Breakdown** is the primary object of this analysis.

I used the R libraries `purrr` and `pdf_tools` to read-in the data to a list of 10 lists of data frames: one data frame for each page, one list for each file, in a collection of 10 files.


```{r}

projectFiles <- dir_ls('../posts/TimShores_FinalProject_Data') # creates fs_path vector of each file in that directory

projectFiles_list <- projectFiles %>%
  map(pdf_data) # purrr function that applies pdf_data reading function to each file element of fs_path vector
  # map creates a list of lists of tibbles (a tibble for each page of each pdf)

  # now that I've consumed my files I can str_replace to get town and year info from each filename.

projectFiles <- projectFiles %>% 
  str_replace('../posts/TimShores_FinalProject_Data/', '') %>%
  str_replace('.pdf', '') 
names(projectFiles_list) <- projectFiles

```

I took the following general steps to parse this list:

::: {.callout-note icon=false}

## Data transformation steps

1. Mutated each row with information about the town, year, and source page number.
2. Flattened the nested list of data frames into a single data frame of all observations that retained the horizontal and vertical arrangement of the tables in the source reports.
3. When pdf_data reads a file, it parses each text box encoded in the PDF as a separate data frame row. It records x and y coordinates of each text box in a data frame variable. Given the regularity of horizontal and vertical alignment of tables in the Central Square report format, this made it possible to identify column boundaries: each column had a minimum and maximum value for x. I used `pivot_wider` to create new variables to temporarily store values based on their horizontal position on the page.
4. The Call Reason Breakdown table in the source reports is a combination of call reasons (each call has a single reason) and call actions (each call has 0, 1, or many actions taken by officers). I focused most of my tidying and transformation steps to teasing apart Call Reason Breakdown observations into separate data frames: one for reasons, another for actions. The source data shows time variables in minutes -- I will convert these to hours.
5. I created a third data frame for operator demographics, although the reports do not show how this data is related to calls.
6. My code removed all NA values. Every observation in the original reports had values for every variable. However, because the Call Reason Breakdown table format staggers data about call reasons and actions, the initial data frame had many NAs. When plyering apart the semantics of reason and action, I interpret NA to indicate that I must remove the row or fill in the variable with a sub-heading value. The end result is three data frames with no NAs.
:::

See my comments in the code block below for details.


```{r}

  # This next part took a couple days of searching for a tidy solution. 
  # Then I just decided to use a good old-fashioned nested for loop.
  # The structure of the original documents is that each of 10 files has a variable number of pages.
  # Therefore, the projectFiles_list structure is a nested list of dataframes: list[[list]][[dataframe]]. 
  # I want to mutate each df with the page number from its PDF, or "innerpageid". 
  # Inner pagination corresponds to each dataframe's nested list element index (j in list[[i]][[j]]) which 
  # is information that gets destroyed as soon as I map to an unnested list. I couldn't find a tidy solution to capturing that nested
  # "inner" page id before the map, so I used a nested for loop to assign value to innerpageid before appending my mapped/mutated df to
  # a new single-layer list.

allYearsList <- list()
for (i in seq_along(projectFiles_list)) { # seq_along(projectFiles_list) creates vector with a number value for each list element
  for (j in seq_along(projectFiles_list[[i]])) {
    projectFiles_list[[i]][[j]] <- mutate(projectFiles_list[[i]][[j]], innerpageid = j)
  }
  allYearsList <- append(allYearsList, map2(projectFiles_list[[i]], 
                                            names(projectFiles_list[i]), 
                                            ~.x %>% 
                                              mutate(filename = .y)
                                            )
                         )
  }

  # this bind_rows takes all of the df observations from all of the list elements and binds them together in a single df.
  # outerpageid is the 'page' number in an absolute sequence (1 to 78 in this case) rather than segmented by file (1 to 9, 1 to 7 etc.)
  # Note that outerpageid is not particularly important (it's semantically identical to town, year, innerpageid) 
  # and I should remove this scaffold.

allYearsDF <- allYearsList %>%
  bind_rows(.id = 'outerpageid') %>% 
  relocate(c(filename, innerpageid), .after = outerpageid) %>%
  filter(height == 11 & y > 13 & text != "Action:")
  
  # this creates a problem of staggered lines

allYearsDF_wide <- allYearsDF %>% 
  pivot_wider(id_cols = c(outerpageid, filename, innerpageid, y), names_from = x, values_from = text)

# solution from https://stackoverflow.com/questions/45515218/combine-rows-in-data-frame-containing-na-to-make-complete-row
# Supply lists by splicing them into dots:

coalesce_by_column <- function(df) {
  return(dplyr::coalesce(!!! as.list(df)))
}

allYearsDF_wide <- allYearsDF_wide %>%
  mutate(outerpageid = as.integer(outerpageid))

allYearsDF_wide <- allYearsDF_wide %>%
  group_by(outerpageid, filename, innerpageid, y) %>% # outerpageid is redundant here
  summarise_all(coalesce_by_column) %>%
  ungroup()
# do I need to ungroup() ? doesn't seem to hurt!

  # it will help to order columns by numeric order - they are the x coords from left to right. This looks for all non-alpha column names.

numcols = sort(as.numeric(names(allYearsDF_wide)[!grepl("[a-z]", names(allYearsDF_wide))]))
allYearsDF_wide <- select(allYearsDF_wide, outerpageid, filename, innerpageid, y, match(numcols, names(allYearsDF_wide))) 

  # now we have a df that is simply x:y coordinates of the page
  # time to smush cols together!

allYearsDF_wide <- unite(allYearsDF_wide, "x5to52", c("5":"47"), sep = " ", na.rm = TRUE, remove = TRUE)
allYearsDF_wide <- unite(allYearsDF_wide, "x53to197", c("53":"197"), sep = " ", na.rm = TRUE, remove = TRUE)
allYearsDF_wide <- unite(allYearsDF_wide, "x198to238", c("198":"233"), sep = " ", na.rm = TRUE, remove = TRUE)
allYearsDF_wide <- unite(allYearsDF_wide, "x239to280", c("239":"270"), sep = " ", na.rm = TRUE, remove = TRUE)
allYearsDF_wide <- unite(allYearsDF_wide, "x281to329", c("281":"329"), sep = " ", na.rm = TRUE, remove = TRUE)
allYearsDF_wide <- unite(allYearsDF_wide, "x330to371", c("330":"371"), sep = " ", na.rm = TRUE, remove = TRUE)
allYearsDF_wide <- unite(allYearsDF_wide, "x372to449", c("372":"431"), sep = " ", na.rm = TRUE, remove = TRUE)
allYearsDF_wide <- unite(allYearsDF_wide, "x450toEnd", c("450":"545"), sep = " ", na.rm = TRUE, remove = TRUE)

  # note that spacing does differ on each page (as indicated by the colnames), but the boundaries are stable
  # (as indicated by the united colnames -- I manually confirmed the minimum pixel position of each column on each data frame)

  # final tidying of Call_Reason text separated into different columns

allYearsDF_wide <- mutate(allYearsDF_wide, 
                          x5to52 = ifelse(nchar(x5to52, type="chars") > 0 & nchar(x53to197, type="chars") > 0, 
                                          paste0(x5to52," ",x53to197), 
                                          paste0(x5to52)),
                          x53to197 = ifelse(nchar(x5to52, type="chars") > 0, 
                                            paste0(""), 
                                            paste0(x53to197))) # delete from additional columns

allYearsDF_wide <- mutate(allYearsDF_wide, 
                          x53to197 = ifelse(x53to197 == "", paste0(""), paste0(x53to197, " ", x198to238, " ", x239to280, " ", x281to329, " ", x330to371, " ", x372to449, " ", x450toEnd)),
                          x198to238 = ifelse(nchar(x53to197, type="chars") > 0, paste0(""), paste0(x198to238)), # delete from add'l cols
                          x239to280 = ifelse(nchar(x53to197, type="chars") > 0, paste0(""), paste0(x239to280)), # delete from add'l cols
                          x281to329 = ifelse(nchar(x53to197, type="chars") > 0, paste0(""), paste0(x281to329)), # delete from add'l cols
                          x330to371 = ifelse(nchar(x53to197, type="chars") > 0, paste0(""), paste0(x330to371)), # delete from add'l cols
                          x372to449 = ifelse(nchar(x53to197, type="chars") > 0, paste0(""), paste0(x372to449)), # delete from add'l cols
                          x450toEnd = ifelse(nchar(x53to197, type="chars") > 0, paste0(""), paste0(x450toEnd)) # delete from add'l cols
                          )

allYearsDF_wide <- allYearsDF_wide %>% mutate_at(c(5,6), ~na_if(., '')) # replace blanks with NAs in the 2nd and 3rd cols. I tried this using paste in the previous mutate, but the result was a text string "NA".

  # label each action with its call reason

allYearsDF_wide <- fill(allYearsDF_wide, x5to52, .direction = "down")

allYearsDF_wide <- allYearsDF_wide %>% 
  mutate(x53to197 = ifelse(row_number() == 1, "Action", x53to197))

colnames(allYearsDF_wide)[-c(1:4)] <- allYearsDF_wide[1,-c(1:4)]

allYearsDF_wide <- allYearsDF_wide %>% 
  rename_with(tolower) %>%
  rename_with(~ gsub("._", "_", .x, fixed = TRUE)) %>%
  rename_with(~ gsub("@", "at", .x, fixed = TRUE)) %>%
  rename(avg_hours_to_arrive = avg_arrive,
         avg_hours_at_scene = avg_time_at_scene) %>%
  filter(innerpageid != 1 | y != 69 | call_reason != "Call_Reason") %>%
  filter(self != "Self_Init") %>%
    # sep filename into town and year
  separate_wider_regex(filename, c(town = "^[A-Za-z]+", year = "[0-9]{4}$")) %>%
  mutate(town = factor(town),
         year = make_date(year = as.integer(year), month = 1, day = 1)) %>%
  select(-c(total, "___%")) %>%
  mutate(across(call_reason:avg_hours_at_scene, ~na_if(., "")))

  # First and second df achievement unlocked:

callReasonsDF <- allYearsDF_wide %>% 
  filter(is.na(action)) %>% 
  #filter(!grepl("total", call_reason, ignore.case = TRUE)) %>%
  filter(!is.na(self)) %>%
  select(town, year, call_reason, self, disp, avg_hours_to_arrive, avg_hours_at_scene) %>%
  mutate(call_reason = factor(call_reason)) %>%
  mutate_at(c("self", "disp"), as.integer) %>%
  mutate_at(c("avg_hours_to_arrive", "avg_hours_at_scene"), as.numeric) %>%
  mutate(
    avg_hours_to_arrive = ifelse(is.na(avg_hours_to_arrive), 0, avg_hours_to_arrive),
    avg_hours_to_arrive = avg_hours_to_arrive / 60, 
    avg_hours_at_scene = avg_hours_at_scene / 60) # convert times to hours

  # keeps only rows with call_reason = TOTAL
totalReasonsDF <- callReasonsDF %>% 
  filter(grepl("^TOTAL$", call_reason, ignore.case = FALSE))

  # gets rid of rows with call_reason = TOTAL
callReasonsDF <- callReasonsDF %>%
  filter(!grepl("total", call_reason, ignore.case = TRUE))

  # Third and fourth df achievement unlocked

callActionsDF <- allYearsDF_wide %>% 
  filter(!is.na(action)) %>%
  filter(!grepl("total", call_reason, ignore.case = TRUE)) %>%
  select(c(town, year, call_reason, action))  %>%
  separate_wider_regex(action, c(actionname = ".+", " = ", actioncount = ".*")) %>%
  mutate(call_reason = factor(call_reason),
         actionname = factor(actionname),
         actioncount = str_squish(actioncount),
         actioncount = as.integer(actioncount))

  # Fourth df achievement unlocked

totalActionsDF <- allYearsDF_wide %>%
  filter(is.na(action), is.na(self)) %>%
  filter(!grepl("total", call_reason, ignore.case = TRUE)) %>%
  select(c(town, year, call_reason, disp)) %>%
  separate_wider_regex(call_reason, c(actionname = "[A-Za-z/()\\-\\s]+", self = "\\s[0-9]{1,4}", ".*")) %>%
  mutate(actionname = factor(actionname),
         self = str_squish(self),
         disp = str_squish(disp)) %>%
  mutate_at(c("self", "disp"), as.integer)

  # Fifth and final df achievement unlocked

operatorSummaryDF <- allYearsDF_wide %>% 
  filter(!is.na(action)) %>%
  filter(grepl("total", call_reason, ignore.case = TRUE)) %>%
  mutate(opcategory = str_extract(action, "Sex|Race|Ethnicity")) %>%
  fill(opcategory) %>%
  filter(!grepl("total", action, ignore.case = TRUE)) %>%
  rename(opid = action) %>%
  select(c(town, year, opcategory, opid))  %>%
  separate_wider_regex(opid, c(opid = "[A-Za-z/\\-\\s]+", opcount = "\\s[0-9]{1,3}", ".+")) %>%
  mutate(opcategory = factor(opcategory),
         opid = str_squish(opid),
         opid = factor(opid),
         opcount = str_squish(opcount),
         opcount = as.integer(opcount))

  
```


### Data Dictionary

These are the final data frame variables: 

::: {.callout-note icon=false}

## callReasonsDF

- **`r colnames(callReasonsDF)[3]`**: factor with 121 levels, describes the type of incident that resulted in a call to LPD or Shelburne Dispatch
- **`r colnames(callReasonsDF)[4]`**: the number of calls per call_reason made directly to LPD (or WPD before 2021)
- **`r colnames(callReasonsDF)[5]`**: the number of calls per call_reason made to Shelburne Dispatch
- **`r colnames(callReasonsDF)[6]`**: time in hours between call received and when the officer arrived on the reported location or 'scene' of the incident
- **`r colnames(callReasonsDF)[7]`**: time in hours between officer arrival and an outcome action (not necessarily the completion of the call itself -- calls may result in one or more new calls, referrals to a third party, an ongoing investigation, or a call that remains open and unresolved with no further action.)
:::

::: {.callout-note icon=false}

## totalReasonsDF

Fetches totals of numeric variables from the report. This is only for quality-assurance comparison with calculated totals of **callReasonsDF** variables.

:::

::: {.callout-note icon=false}

## callActionsDF

- **`r colnames(callActionsDF)[3]`**: Factor with 121 levels, same as in callReasonsDF
- **`r colnames(callActionsDF)[4]`**: Factor with 47 levels, one for each action outcome for a call
- **`r colnames(callActionsDF)[5]`**: Count of actionnames for each call_reason
:::

::: {.callout-note icon=false}

## totalActionsDF

Fetches totals from the **Call Action Breakdown** table. This supports quality-assurance comparison with calculated totals of **callActionsDF** variables. However the **Call Action Breakdown** table also attributes action counts to calls directly to the local police department and to Shelburne Dispatch. This information is not available in the **Call Reason Breakdown** table.

- **`r colnames(totalActionsDF)[4]`**: Count of actionnames for calls made directly to LPD (or WPD before 2021).
- **`r colnames(totalActionsDF)[5]`**: Count of actionnames for calls made to Shelburne Dispatch.

:::

::: {.callout-note icon=false}
## operatorSummaryDF

- **`r colnames(operatorSummaryDF)[3]`**: Factor with 3 levels: Ethnicity, Race, or Sex
- **`r colnames(operatorSummaryDF)[4]`**: Factor with 11 levels corresponding to specific ethnicity, races, sexes
- **`r colnames(operatorSummaryDF)[4]`**: Count of vehicle operators for each opid
:::

::: {.callout-note icon=false}

## Key variables

Each data frame includes the following variables that identify when and where the incident and response happened:

- **`r colnames(callReasonsDF)[1]`**: 2-level factor, Leverett or Wendell
- **`r colnames(callReasonsDF)[2]`**: date, 2018 to 2022 (in all cases, month = 1 and day = 1)

I can join reason and action data by using town, year, and call_reason as a compound key.
:::

Finally, I created a dataframe of 11 "public safety themes" mapped to each of the 121 call reasons that I can use to analyze the dataset in simpler terms. This is my own subjective interpretation of public safety themes, and I will remain open to feedback and referrals to standard taxonomies, if any exist. One of the dilemmas of analyzing police data is a lack of clear policing data standards. 

::: {.callout-note icon=false}

## Public safety themes

- Administration
- Fire
- Medical
- Mental Health or Social Work
- Nonviolent Crime
- Other Safety
- Prevention
- Utility
- Vehicular
- Violent Crime

:::

The LPD call data does not show when police response is required. These themes permit interpretations of call volume and time according to when police response is required in comparison with the calls that a police officer responds to because another type of first responder is not available.

```{r}

callReasonNameFactors = c("209A SERVICE", "209A VIOLATION", "911 CALL", "911 HANG UP", "911 MIS DIAL", "911 Text to 911", "ABANDONED 911 CALL", "ABANDONED MV", "ADMINISTRATIVE", "ALARM BURGLAR OR HOLDUP", "ANIMAL COMPLAINT", "ANNOYING PHONE CALLS", "ARTICLES LOST", "ARTICLES RECOVERED", "ASSAULT", "ASSIST CITIZEN", "ASSIST OTHER AGENCY", "BE ON THE LOOK OUT", "BREAKING & ENTERING AUTO", "BREAKING & ENTERING PAST", "BREAKING AND ENTERING", "BRUSH FIRE", "BUILDING/LOCATION CHECK", "BURN/AGRI PERMIT", "BYLAW VIOLATION", "Car vs. Deer", "CARBON MONOXIDE HAZARD", "CHECK WELFARE", "CHIMNEY FIRE", "Civil Issue", "COMMUNITY POLICING", "COMPLAINT", "COURT", "CRUISER MAINTENANCE", "CSO FOLLOW UP", "CSO OUTREACH", "CUSTODY ISSUE", "DEATH", "DETAIL REQUEST", "DISABLED MV", "DISTURBANCE", "DOMESTIC", "Drill/Testing", "DRUG OFFENSE", "DRUNK", "EMS ALARM - LIFELINE ACTIVATED", "ESCORT/TRANSPORT", "EXPLOSION", "FIGHT", "FIRE ALARM", "FIRE WORKS", "FIRE, OTHER NON-SPECIFIC", "FIREARMS LICENSING", "FOLLOW UP INVESTIGATION", "FRAUD/SCAM", "GAS LEAK", "GENERAL INFO", "HARASSMENT", "HIT AND RUN", "ILLEGAL BURN", "ILLEGAL DUMPING", "INVESTIGATION", "JUVENILE OFFENSES", "KEEP THE PEACE", "LARCENY", "LINE DOWN, POWER,PHONE OR CABL", "LOCKOUT", "MEDICAL EMERGENCY", "MISCELLANEOUS", "MISSING PERSON", "MOTOR VEHICLE - STOLEN", "MOTOR VEHICLE ACCIDE W/INJURY", "MOTOR VEHICLE ACCIDENT NO INJU", "MOTOR VEHICLE COMPLAINT", "MOTOR VEHICLE RECOVERED", "MOTOR VEHICLE VIOLATION", "NOISE COMPLAINT", "NOTIFICATION", "ODOR INVESTIGATION", "OFFICER WANTED", "OPEN DOOR", "Paid Detail", "PAPERWORK SERVICE", "PARKING COMPLAINT", "PATROL AREA", "POWER OUTAGE/FAILURE", "RADAR/TRAFFIC ENFORCEMENT", "RAPE", "REPOSSESSION", "RESCUE CALL", "ROLLING 9", "ROLLING Q2-1", "RUNAWAY", "SAFETY HAZARD", "SCHOOL RESOURCE OFFICER DUTIES", "SEARCH", "Section 12", "SERVE WARRANT", "SERVICE CALL", "SEX OFFENDER REGISTRATION", "SHOPLIFTING", "SHOTS FIRED", "SMOKE INVESTIGATION", "SOLICITING", "STRUCTURE FIRE", "SUICIDE COMMITTED", "SUICIDE THREAT", "SUMMONS SERVICE", "SUSPICIOUS ACTIVITY", "SUSPICIOUS PACKAGE", "SUSPICIOUS PERSON", "SUSPICIOUS VEHICLE", "SWATTING", "THREAT", "TRAFFIC CONTROL", "TRAFFIC HAZARD", "TRESPASS", "TRUANT", "UNWANTED PERSON", "VANDALISM", "VEHICLE FIRE")

callReasonNameThemes = c("Mental Health or Social Work", "Mental Health or Social Work", "Other Safety", "Administration", "Administration", "Administration", "Administration", "Vehicular", "Administration", "Violent Crime", "Other Safety", "Other Safety", "Other Safety", "Administration", "Violent Crime", "Other Safety", "Other Safety", "Other Safety", "Nonviolent Crime", "Nonviolent Crime", "Violent Crime", "Fire", "Prevention", "Fire", "Nonviolent Crime", "Vehicular", "Fire", "Prevention", "Fire", "Mental Health or Social Work", "Prevention", "Other Safety", "Administration", "Administration", "Mental Health or Social Work", "Mental Health or Social Work", "Mental Health or Social Work", "Other Safety", "Administration", "Vehicular", "Other Safety", "Violent Crime", "Administration", "Mental Health or Social Work", "Mental Health or Social Work", "Medical", "Other Safety", "Fire", "Violent Crime", "Fire", "Fire", "Fire", "Administration", "Administration", "Nonviolent Crime", "Utility", "Administration", "Nonviolent Crime", "Violent Crime", "Fire", "Nonviolent Crime", "Administration", "Mental Health or Social Work", "Prevention", "Nonviolent Crime", "Utility", "Other Safety", "Medical", "Other Safety", "Other Safety", "Nonviolent Crime", "Medical", "Vehicular", "Vehicular", "Vehicular", "Vehicular", "Nonviolent Crime", "Administration", "Other Safety", "Other Safety", "Prevention", "Administration", "Administration", "Vehicular", "Prevention", "Utility", "Vehicular", "Violent Crime", "Other Safety", "Other Safety", "Vehicular", "Vehicular", "Mental Health or Social Work", "Other Safety", "Administration", "Other Safety", "Mental Health or Social Work", "Administration", "Administration", "Prevention", "Nonviolent Crime", "Violent Crime", "Fire", "Nonviolent Crime", "Fire", "Mental Health or Social Work", "Mental Health or Social Work", "Administration", "Prevention", "Prevention", "Prevention", "Prevention", "Violent Crime", "Nonviolent Crime", "Vehicular", "Vehicular", "Nonviolent Crime", "Mental Health or Social Work", "Other Safety", "Nonviolent Crime", "Fire")

factorThemesDF <- data.frame(call_reason = callReasonNameFactors, call_theme = callReasonNameThemes) %>%
  mutate(call_reason = factor(call_reason),
         call_theme = factor(call_theme))

callReasonsDF <- left_join(callReasonsDF, factorThemesDF, by ='call_reason')
callActionsDF <- left_join(callActionsDF, factorThemesDF, by ='call_reason')

```

To get a sense of the scale of time spent on calls, these 3 tables show (1) a summary of time per call by the top 5 call reason mean times; (2) a summary of time per call by town; and (3)  a summary of time per year.

```{r}

#define function to calculate mode
find_mode <- function(x) {
  u <- unique(x[!is.na(x)]) # unique list as an index, without NA
  tab <- tabulate(match(x[!is.na(x)], u))  # count how many times each index member occurs
  u[tab == max(tab)] #  the max occurrence is the mode
  mean(u) # return mean in case the data is multimodal
}


callReasonsDF_ReasonSummary <- callReasonsDF %>% 
  mutate(avg_hours_per_call = avg_hours_to_arrive + avg_hours_at_scene) %>%
  group_by(call_reason) %>% 
  summarise(
    meanHrs = mean(avg_hours_per_call, na.rm = TRUE), 
    modeHrs = find_mode(avg_hours_per_call), 
    minHrs = fivenum(avg_hours_per_call, na.rm = TRUE)[1], 
    lHingeHrs = fivenum(avg_hours_per_call, na.rm = TRUE)[2], 
    medHrs = median(avg_hours_per_call, na.rm = TRUE), 
    uHingeHrs = fivenum(avg_hours_per_call, na.rm = TRUE)[4], 
    maxHrs = fivenum(avg_hours_per_call, na.rm = TRUE)[5]
    ) %>%
  arrange(desc(meanHrs))

crReasonRoundedDF <- callReasonsDF_ReasonSummary %>% 
  mutate_if(is.numeric, round, digits = 2)
head(crReasonRoundedDF, 5)


callReasonsDF_TownSummary <- callReasonsDF %>% 
  mutate(avg_hours_per_call = avg_hours_to_arrive + avg_hours_at_scene) %>%
  group_by(town) %>% 
  summarise(
    meanHrs = mean(avg_hours_per_call, na.rm = TRUE), 
    modeHrs = find_mode(avg_hours_per_call), 
    minHrs = fivenum(avg_hours_per_call, na.rm = TRUE)[1], 
    lHingeHrs = fivenum(avg_hours_per_call, na.rm = TRUE)[2], 
    medHrs = median(avg_hours_per_call, na.rm = TRUE), 
    uHingeHrs = fivenum(avg_hours_per_call, na.rm = TRUE)[4], 
    maxHrs = fivenum(avg_hours_per_call, na.rm = TRUE)[5]
    ) %>%
  arrange(desc(meanHrs))

crTownRoundedDF <- callReasonsDF_TownSummary %>% 
  mutate_if(is.numeric, round, digits = 2)
crTownRoundedDF


callReasonsDF_YearSummary <- callReasonsDF %>% 
  mutate(avg_hours_per_call = avg_hours_to_arrive + avg_hours_at_scene) %>%
  group_by(year) %>% 
  summarise(
    meanHrs = mean(avg_hours_per_call, na.rm = TRUE), 
    modeHrs = find_mode(avg_hours_per_call), 
    minHrs = fivenum(avg_hours_per_call, na.rm = TRUE)[1], 
    lHingeHrs = fivenum(avg_hours_per_call, na.rm = TRUE)[2], 
    medHrs = median(avg_hours_per_call, na.rm = TRUE), 
    uHingeHrs = fivenum(avg_hours_per_call, na.rm = TRUE)[4], 
    maxHrs = fivenum(avg_hours_per_call, na.rm = TRUE)[5]
    ) %>%
  arrange(desc(meanHrs))

crYearRoundedDF <- callReasonsDF_YearSummary %>% 
  mutate_if(is.numeric, round, digits = 2)
crYearRoundedDF

```

### Analysis Plan

My goal is to analyze and visualize call data in answer to this question: 

::: {.callout-warning icon=false}

## Research question

**What is the nature of public safety need behind the increase in calls that police respond to?**

:::

My analysis plan is to answer the following more specific questions for both towns together, and compared between towns: 

::: {.callout-warning icon=false}

## Specific question for analysis

1. Has call volume grown over time?
2. What call reasons have grown over time?
3. Which call reasons require the most personnel time, and how has this changed from 2018 to 2022?
4. Which call actions are associated with the most time-consuming call reasons, and how has this changed?
5. Leverett and Wendell began a regionalization agreement in 2020. How has that impacted the data of time spent on calls?
6. Are there differences in call volume, reasons, actions, and themes made directly to the local PD and to Shelburne Dispatch?
7. How often does the LPD refer calls to third parties?
:::



### Results: Analysis and Visualization

What types of calls are increasing?
What is the change in personnel time needed per call and per type of call?
What days and times of day do we see the most calls or the most change in calls?
Why do we need another officer when the populations and number of properties in the two towns have not grown substantially?

## Call Volume

Three key metrics are the number of calls (call volume), average hours worked, and total hours worked. The first question for a municipal department is about what impacts the budget. The change in total hours worked over time shows the big picture:

```{r chunkTotalHours, fig.width=10, fig.height=5}

#myPalette <- c('#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6','#6a3d9a')

# initialize all dfs used below

# group by year
crYearDF <- callReasonsDF %>%
  group_by(year) %>%
  summarise(
    callTotal = sum(self) + sum(disp),
    avgHours = mean(avg_hours_to_arrive + avg_hours_at_scene),
    callTotalHours = callTotal * avgHours
  ) 

# group by town and year
crTownYearDF <- callReasonsDF %>%
  group_by(town, year) %>%
  summarise(
    callTotal = sum(self) + sum(disp),
    avgHours = mean(avg_hours_to_arrive + avg_hours_at_scene),
    callTotalHours = callTotal * avgHours
  ) 

# group by year and theme
crThemeYear <- callReasonsDF %>%
  group_by(call_theme, year) %>%
    summarise(
    callTotal = sum(self) + sum(disp),
    avgHours = mean(avg_hours_to_arrive + avg_hours_at_scene),
    callTotalHours = callTotal * avgHours
  )

## comparing reasons - what is this for again?
crCompareReasons <- callReasonsDF %>%
  mutate(callTotal = self + disp,
         avgHours = avg_hours_to_arrive + avg_hours_at_scene,
         callTotalHours = callTotal * avgHours) %>%
  arrange(desc(callTotalHours)) 

### first plot shows the big picture: change in total hours

crYearDF %>%
  select(year, callTotalHours) %>%
  ggplot(aes(x = year, y = callTotalHours)) + 
    geom_area(alpha = 0.5) +
    labs(title = "Total hours working on calls",
         y = "Calls") +
    geom_smooth(method = lm,
                se = FALSE, 
                linewidth = 1.5,
                color = "orangered") + 
    scale_fill_viridis(discrete = T, option = "cividis") +
    theme_ipsum() +
    theme(axis.text.x = element_text(angle = 90))

crYearDF %>%
  select(year, callTotalHours)

```

The big picture shows `r crYearDF[5,4] / crYearDF[1,4] * 100`% growth in total hours worked by police officers in the two towns together from `r year(crYearDF[1,1])` 


Faceting the 3 key metrics by town lets us compare the change in calls and hours worked over the 5-year period:

```{r chunkByTown, fig.width=10, fig.height=10}

  # total call volume by town
g1 <- crTownYearDF %>%
ggplot(aes(x = year, y = callTotal, fill = town)) + 
  geom_area(alpha = 0.5, color = "white") +
  labs(title = "Total call volume by town",
       y = "Calls") +
  geom_smooth(method = lm,
              se = FALSE, 
              linewidth = 1.5,
              color = "orangered") +
  scale_fill_viridis(discrete = T, option = "cividis") +
  theme_ipsum() +
  theme(axis.text.x = element_text(angle = 90)) +
  facet_wrap(vars(town))

  # avg hours per call by town
g2 <- crTownYearDF %>%
ggplot(aes(x = year, y = avgHours, fill = town)) + 
  geom_area(alpha = 0.5, color = "white") +
  labs(title = "Average hours per call by town",
       y = "Hours") +
  geom_smooth(method = lm,
              se = FALSE, 
              linewidth = 1.5,
              color = "orangered") +
  scale_fill_viridis(discrete = T, option = "cividis") +
  theme_ipsum() +
  theme(axis.text.x = element_text(angle = 90)) +
  facet_wrap(vars(town))

  # total hours by town
g3 <- crTownYearDF %>%
ggplot(aes(x = year, y = callTotalHours, fill = town)) + 
  geom_area(alpha = 0.5, color = "white") +
  labs(title = "Total hours by town",
       y = "Hours") +
  geom_smooth(method = lm,
              se = FALSE, 
              linewidth = 1.5,
              color = "orangered") +
  scale_fill_viridis(discrete = T, option = "cividis") +
  theme_ipsum() +
  theme(axis.text.x = element_text(angle = 90)) +
  facet_wrap(vars(town))

grid.arrange(g1, g2, g3, nrow = 3)

```



```{r name-of-chunk, fig.width=10, fig.height=10}

  
sumCRTownYearTheme %>% # order themes by callTotal
  mutate(call_theme = fct_reorder(call_theme, callTotal, .fun = 'sum')) %>%
  ggplot(aes(x = year, y = callTotal, fill = call_theme)) +
    geom_area() +
    labs(title = "Total police call volume by call theme", 
         y = "Calls") + 
    scale_fill_manual(values = myPalette[1:10]) # to establish consistent colors between graphs, this maps max callTotal = color 1, min callTotal = color 10


sumCRTownYearTheme %>% 
  slice_max(order_by = callTotal, n = 5) %>%
  mutate(call_theme = fct_reorder(call_theme, callTotal, .fun = 'sum')) %>%
  ggplot(aes(x = year, y = callTotal, fill = call_theme)) +
    geom_area() +
    labs(title = "Call volume, zoom in on top 5 call themes", 
         y = "Calls") +
    scale_fill_manual(values = myPalette[c(6:10)]) # consistent colors between graphs

# sumCRTownYearTheme %>% 
#   slice_min(order_by = callTotal, n = 5) %>%
#   mutate(call_theme = fct_reorder(call_theme, callTotal, .fun = 'sum')) %>%  
#   ggplot(aes(x = year, y = callTotal, fill = call_theme)) +
#     geom_area() +
#     labs(title = "Call volume, bottom 5 call themes in each year", 
#          subtitle = "Y-axis at same scale as top 5 call themes",
#          y = "Calls") +
#     ylim(0, 4000) + 
#     scale_fill_manual(values = myPalette[c(1:5)]) # consistent colors between graphs

# sumCRTownYearTheme %>% 
#   slice_min(order_by = callTotal, n = 5) %>%
#   mutate(call_theme = fct_reorder(call_theme, callTotal, .fun = 'sum')) %>%    
#   ggplot(aes(x = year, y = callTotal, fill = call_theme)) +
#     geom_area() +
#     labs(title = "Call volume, bottom 5 call themes in each year", 
#          subtitle = "Y-axis at 1/4 scale of top 5 call themes",
#          y = "Calls") +
#     ylim(0, 1000) + 
#     scale_fill_manual(values = myPalette[c(1:5)]) # consistent colors between graphs

sumCRTownYearTheme %>% 
  slice_min(order_by = callTotal, n = 5) %>%
  mutate(call_theme = fct_reorder(call_theme, callTotal, .fun = 'sum')) %>%    
  ggplot(aes(x = year, y = callTotal, fill = call_theme)) +
    geom_area() +
    labs(title = "Call volume, zoom in on bottom 5 call themes", 
         subtitle = "Y-axis at 1/10 scale of top 5 call themes",
         y = "Calls") +
    ylim(0, 400) + 
    scale_fill_manual(values = myPalette[c(1:5)]) # consistent colors between graphs

```

# Officer hours on calls - average and total

```{r}


#   # Goal: use facet to compare total hour growth to total call volume growth by town
# callReasonsDF %>% 
# ggplot(aes(x = year, y = avg_hours_to_arrive + avg_hours_at_scene)) + 
#   geom_area() +
#   labs(title = "Average police officer hours on all calls by town",
#        y = "Hours") +
#   geom_smooth(method = lm, 
#               se = FALSE,
#               color = "Black") +
#   scale_fill_manual(values = myPalette[c(1,2)]) + # consistent colors between graphs
#   facet_grid(call_theme ~ town)


  # avgHours by town
sumCRTownYear %>% 
ggplot(aes(x = year, y = avgHours, fill = town)) + 
  geom_area() +
  labs(title = "Average hours per call by town",
       y = "Hours") +
  geom_smooth(method = lm, 
              se = FALSE,
              color = "Black") +
  scale_fill_manual(values = myPalette[c(1,2)]) # consistent colors between graphs


  # callTotalHours by town
sumCRTownYear %>% 
ggplot(aes(x = year, y = callTotalHours, fill = town)) + 
  geom_area() +
  labs(title = "Total hours by town",
       y = "Hours") +
  geom_smooth(method = lm, 
              se = FALSE,
              color = "Black") +
  scale_fill_manual(values = myPalette[c(1,2)]) # consistent colors between graphs

  # avgHours by all themes
# sumCRTownYearTheme %>% 
#   mutate(call_theme = fct_reorder(call_theme, avgHours, .fun = 'sum')) %>%
#   ggplot(aes(x = year, y = avgHours, fill = call_theme)) +
#     geom_area() +
#     labs(title = "Average police officer hours by call theme", 
#          y = "Hours") + 
#     scale_fill_manual(values = myPalette[1:10]) # consistent colors between graphs

###
###
###


# this works, and shows relationship between reason and theme
crCompareReasons  %>%
  group_by(call_reason, call_theme, town) %>%
    summarise(
    callTotalHours = sum(callTotalHours)
  ) %>%
  arrange(desc(callTotalHours)) %>%
  head(20) %>%
  ggplot(aes(x = call_theme, y = callTotalHours, fill = call_reason)) +
    theme(axis.text.x = element_text(angle = 90)) +
    geom_bar(stat = "identity") +  
      labs(title = "Top 20 call reasons by total hours",
           subtitle = "Both towns and all years (2018 to 2022)",
           y = "Hours") +
    #scale_fill_manual(values = myPalette) + # too many values
    facet_wrap(vars(town))


crCompareReasons %>%
  group_by(call_reason, town) %>%
    summarise(
    callTotalHours = sum(callTotalHours)
  ) %>%
  ggplot(aes(town, callTotalHours)) +
    geom_boxplot() +
    scale_y_continuous(limits = quantile(crCompareReasons$callTotalHours, c(0.05, 0.95)))

# this is the key to getting factors of top call reasons by hours worked
topfactors <- crCompareReasons %>%
  group_by(call_reason) %>%
    summarise(
    callTotalHours = sum(callTotalHours)
  ) %>%
  subset(callTotalHours < quantile(crCompareReasons$callTotalHours, 0.99)) %>% # complement
  droplevels.data.frame()

# this works!
crCompareReasons %>%
  group_by(call_reason, year) %>%
    summarise(
    callTotalHours = sum(callTotalHours)
  ) %>%
  droplevels.data.frame(exclude = c(levels(topfactors[[1]]))) %>% 
  filter(!is.na(call_reason)) %>%
  ggplot(aes(x = year, y = callTotalHours, fill = call_reason)) +
    geom_area() +
    theme(axis.text.x = element_text(angle = 90)) +
      labs(title = "Top level-of-effort call reasons",
           subtitle = "total hours > than 99% of total hours",
           y = "Hours") +
    scale_fill_manual(values = myPalette) + 
    facet_wrap(~call_reason)

# #2 this doesn't work for some reason
topfactors <- crCompareReasons %>%
  group_by(call_reason) %>%
    summarise(
    callTotalHours = sum(callTotalHours)
  ) %>%
  subset(callTotalHours = quantile(crCompareReasons$callTotalHours, c(0.98, 0.99))) %>% # complement
  droplevels.data.frame()

# #2 this doesn't work for some reason
crCompareReasons %>%
  group_by(call_reason, year) %>%
    summarise(
    callTotalHours = sum(callTotalHours)
  ) %>%
  droplevels.data.frame(exclude = c(levels(topfactors[[1]]))) %>% 
  filter(!is.na(call_reason)) %>%
  ggplot(aes(x = year, y = callTotalHours, fill = call_reason)) +
    geom_area() +
    theme(axis.text.x = element_text(angle = 90)) +
      labs(title = "Top level-of-effort call reasons",
           subtitle = "total hours > than 99% of total hours",
           y = "Hours") +
    scale_fill_manual(values = myPalette) + 
    facet_wrap(~call_reason)

  # avgHours over time by reasons, facets
sumCRTownYearTheme %>% 
  ggplot(aes(x = year, y = avgHours, fill = call_theme)) +
    geom_area() +
    theme(axis.text.x = element_text(angle = 90)) +
    labs(title = "Average hours per call", 
         y = "Hours") +
    scale_fill_manual(values = myPalette) + # consistent colors between graphs
    facet_wrap(~call_theme, nrow = 2)

  # callTotalHours over time by themes, facets
sumCRTownYearTheme %>% 
  ggplot(aes(x = year, y = callTotalHours, fill = call_theme)) +
    geom_area() +
    theme(axis.text.x = element_text(angle = 90)) +
    labs(title = "Total hours", 
         y = "Hours") + 
    scale_fill_manual(values = myPalette) + # consistent colors between graphs
    facet_wrap(~call_theme, nrow = 2)

  # avgHours over time by themes, facets
sumCRTownYearTheme %>% 
  ggplot(aes(x = year, y = avgHours, fill = call_theme)) +
    geom_area() +
    theme(axis.text.x = element_text(angle = 90)) +
    labs(title = "Average hours per call", 
         y = "Hours") +
    scale_fill_manual(values = myPalette) + # consistent colors between graphs
    facet_wrap(~call_theme, nrow = 2)


  # callTotalHours by top 6 themes
sumCRTownYearTheme %>% 
  slice_max(order_by = callTotalHours, n = 6) %>%
  mutate(call_theme = fct_reorder(call_theme, callTotalHours, .fun = 'sum')) %>%
  ggplot(aes(x = year, y = callTotalHours, fill = call_theme)) +
    geom_area() +
    labs(title = "Total hours: Zoom in on top 6 call themes", 
         y = "Hours") +
    scale_fill_manual(values = myPalette[c(5:10)]) # consistent colors between graphs





# 
#   # avgHours by bottom 5 themes
# sumCRTownYearTheme %>% 
#   slice_min(order_by = avgHours, n = 5) %>%
#   mutate(call_theme = fct_reorder(call_theme, avgHours, .fun = 'sum')) %>%    
#   ggplot(aes(x = year, y = avgHours, fill = call_theme)) +
#     geom_area() +
#     labs(title = "Average hours, bottom 5 call themes in each year", 
#          y = "Calls") +
#     scale_fill_manual(values = myPalette[c(1:6)]) # consistent colors between graphs
# 
#   # callTotalHours by bottom 5 themes
# sumCRTownYearTheme %>% 
#   slice_min(order_by = callTotalHours, n = 5) %>%
#   mutate(call_theme = fct_reorder(call_theme, callTotalHours, .fun = 'sum')) %>%    
#   ggplot(aes(x = year, y = callTotalHours, fill = call_theme)) +
#     geom_area() +
#     labs(title = "Total hours, bottom 5 call themes in each year", 
#          y = "Calls") +
#     scale_fill_manual(values = myPalette[c(1:5)]) # consistent colors between graphs
# 




```


Visualization will include: 

- The change in average and total time on call response over the years, between the two towns. 
- Call reasons by volume and time over the years, between the two towns. 
- Call actions by call reason volume and time over the years, between the two towns.
- Call volume and time over the years, between the two towns, grouped by public safety themes.




(STORY) Any additional analysis details, and perhaps a backreference to your analysis plan from section 5. (not needed if section 6 is collapsed with sections 2-4)
(CODE-Optional) Statistical Analyses: see “Role of Statistics”
(CODE) Visualization
You should organize your graphs and pictures by a small set of topics/questions
There is no strict requirement on the number of graphs/figures you should make. However, we expect you to present sufficient graphs that are necessary to answer the question.
(STORY) Interpret your analyses and visualization results for the reader
What information do the analysis results or graphs tell you?
You should describe the information of graphs comprehensively and detailed enough for readers to picture or envision the graphs in their brains.

https://dacss.github.io/601_Fall_2022_final_posts/posts/final_project_Guanhua_Tan.html#painting-a-global-map

### Conclusion and Discussion
(STORY) Conclusion and Discussion 
A brief summary of your work and your findings. What is (are) the answer(s) to your question?
(optional) Discuss the limitation of your analyses and visualization; and what further analyses or visualizations you would conduct in the future


### Bibliography
Hint: at minimum, you should cite the source of the dataset and R as a programming language.
	- Any citation style is appropriate since students come from diverse academic backgrounds. Please use whichever style is appropriate for your work.


```{r}
######### all good up to this point.
######### sanity tests
######### make more pipelines

### rubrick items
# 1 
# Communication suitable for an expert and general audience
# 2
# Data cleaning and recoding choices and justification
# 3
# Data driven story-telling (using data to answer questions)
# 4
# Effective and efficient coding



## testers
allYearsDF_wideACTION <- arrange(allYearsDF_wide, Action)
allYearsDF_wideSELF <- arrange(allYearsDF_wide, desc(Self)) # checks out 

# sanity check ... pass!
callReasonsDF %>%
  group_by(town) %>%
  summarise(selfSum = sum(as.numeric(self)), dispSum = sum(as.numeric(disp)), arriveSum = sum(as.numeric(avg_hours_to_arrive)), sceneSum = sum(as.numeric(avg_hours_at_scene)), .groups = 'drop')

```


